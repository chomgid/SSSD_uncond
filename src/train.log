{'diffusion_config': {'T': 200, 'beta_0': 0.0001, 'beta_T': 0.02}, 'wavenet_config': {'in_channels': 8, 'out_channels': 8, 'num_res_layers': 36, 'res_channels': 256, 'skip_channels': 256, 'diffusion_step_embed_dim_in': 128, 'diffusion_step_embed_dim_mid': 512, 'diffusion_step_embed_dim_out': 512, 's4_lmax': 1000, 's4_d_state': 64, 's4_dropout': 0.0, 's4_bidirectional': 1, 's4_layernorm': 1, 'label_embed_dim': 128, 'label_embed_classes': 71}, 'train_config': {'output_directory': '../results', 'ckpt_iter': 'max', 'iters_per_ckpt': 4000, 'iters_per_logging': 100, 'n_iters': 100000, 'learning_rate': 0.0002, 'batch_size': 8}, 'trainset_config': {'segment_length': 1000, 'sampling_rate': 100, 'finetune_dataset': 'ptbxl_all'}, 'gen_config': {'output_directory': '../results', 'ckpt_path': '../results/'}}
output directory ../results/ch256_T200_betaT0.02
Successfully loaded model at iteration 48000
iteration: 48100 	loss: 0.02836364135146141
iteration: 48200 	loss: 0.054565735161304474
iteration: 48300 	loss: 0.01219864096492529
iteration: 48400 	loss: 0.018857667222619057
iteration: 48500 	loss: 0.02747751772403717
iteration: 48600 	loss: 0.027316929772496223
iteration: 48700 	loss: 0.044689472764730453
iteration: 48800 	loss: 0.035833120346069336
iteration: 48900 	loss: 0.011625861749053001
iteration: 49000 	loss: 0.05566626042127609
iteration: 49100 	loss: 0.015360311605036259
iteration: 49200 	loss: 0.050251394510269165
iteration: 49300 	loss: 0.023635320365428925
iteration: 49400 	loss: 0.045067716389894485
iteration: 49500 	loss: 0.008294771425426006
iteration: 49600 	loss: 0.015766309574246407
iteration: 49700 	loss: 0.0137550113722682
iteration: 49800 	loss: 0.01772894524037838
iteration: 49900 	loss: 0.013920880854129791
iteration: 50000 	loss: 0.023621656000614166
iteration: 50100 	loss: 0.06752526015043259
iteration: 50200 	loss: 0.0322284959256649
iteration: 50300 	loss: 0.019412435591220856
iteration: 50400 	loss: 0.013839016668498516
iteration: 50500 	loss: 0.06185959652066231
iteration: 50600 	loss: 0.0068051451817154884
iteration: 50700 	loss: 0.029215408489108086
iteration: 50800 	loss: 0.029767949134111404
iteration: 50900 	loss: 0.03172391653060913
iteration: 51000 	loss: 0.03277076408267021
iteration: 51100 	loss: 0.02873639389872551
iteration: 51200 	loss: 0.01306669320911169
iteration: 51300 	loss: 0.008272464387118816
iteration: 51400 	loss: 0.07970526069402695
iteration: 51500 	loss: 0.023173194378614426
iteration: 51600 	loss: 0.04595441743731499
iteration: 51700 	loss: 0.009927512146532536
iteration: 51800 	loss: 0.02356722578406334
iteration: 51900 	loss: 0.016289496794342995
iteration: 52000 	loss: 0.011932525783777237
model at iteration 52000 is saved
iteration: 52100 	loss: 0.015389150008559227
iteration: 52200 	loss: 0.011672893539071083
iteration: 52300 	loss: 0.011325424537062645
iteration: 52400 	loss: 0.0120474798604846
iteration: 52500 	loss: 0.010720145888626575
iteration: 52600 	loss: 0.016390405595302582
iteration: 52700 	loss: 0.020992452278733253
iteration: 52800 	loss: 0.00898558646440506
iteration: 52900 	loss: 0.01451819110661745
iteration: 53000 	loss: 0.013565845787525177
iteration: 53100 	loss: 0.02015198953449726
iteration: 53200 	loss: 0.021543456241488457
iteration: 53300 	loss: 0.022715769708156586
iteration: 53400 	loss: 0.0342889241874218
iteration: 53500 	loss: 0.010867606848478317
iteration: 53600 	loss: 0.03021501936018467
iteration: 53700 	loss: 0.043367594480514526
iteration: 53800 	loss: 0.03663536533713341
iteration: 53900 	loss: 0.013286450877785683
iteration: 54000 	loss: 0.05809755250811577
iteration: 54100 	loss: 0.05823969468474388
iteration: 54200 	loss: 0.04349292069673538
iteration: 54300 	loss: 0.08778509497642517
iteration: 54400 	loss: 0.039376113563776016
iteration: 54500 	loss: 0.0333264134824276
iteration: 54600 	loss: 0.013056661933660507
iteration: 54700 	loss: 0.03856280446052551
iteration: 54800 	loss: 0.007234164047986269
iteration: 54900 	loss: 0.026134872809052467
iteration: 55000 	loss: 0.03784193471074104
iteration: 55100 	loss: 0.019847096875309944
iteration: 55200 	loss: 0.01771935634315014
iteration: 55300 	loss: 0.0305560864508152
iteration: 55400 	loss: 0.017248859629034996
iteration: 55500 	loss: 0.028188975527882576
iteration: 55600 	loss: 0.010757915675640106
iteration: 55700 	loss: 0.02534840814769268
iteration: 55800 	loss: 0.032468583434820175
iteration: 55900 	loss: 0.0257627721875906
iteration: 56000 	loss: 0.036197174340486526
model at iteration 56000 is saved
iteration: 56100 	loss: 0.007614015601575375
iteration: 56200 	loss: 0.00867967214435339
iteration: 56300 	loss: 0.043830275535583496
iteration: 56400 	loss: 0.03873232752084732
iteration: 56500 	loss: 0.016120901331305504
iteration: 56600 	loss: 0.10575777292251587
iteration: 56700 	loss: 0.0447295717895031
iteration: 56800 	loss: 0.013461003080010414
iteration: 56900 	loss: 0.01670723222196102
iteration: 57000 	loss: 0.08898121863603592
iteration: 57100 	loss: 0.023140141740441322
iteration: 57200 	loss: 0.03375401347875595
iteration: 57300 	loss: 0.026321817189455032
iteration: 57400 	loss: 0.01419180165976286
iteration: 57500 	loss: 0.011009279638528824
iteration: 57600 	loss: 0.02188597247004509
iteration: 57700 	loss: 0.03479204326868057
iteration: 57800 	loss: 0.013221386820077896
iteration: 57900 	loss: 0.025644032284617424
iteration: 58000 	loss: 0.022747453302145004
iteration: 58100 	loss: 0.016121456399559975
iteration: 58200 	loss: 0.006318856496363878
iteration: 58300 	loss: 0.024550557136535645
iteration: 58400 	loss: 0.14145557582378387
iteration: 58500 	loss: 0.020397668704390526
iteration: 58600 	loss: 0.00915648601949215
iteration: 58700 	loss: 0.016690824180841446
iteration: 58800 	loss: 0.008486814796924591
iteration: 58900 	loss: 0.06433148682117462
iteration: 59000 	loss: 0.008940818719565868
iteration: 59100 	loss: 0.012209691107273102
iteration: 59200 	loss: 0.019970595836639404
iteration: 59300 	loss: 0.013962031342089176
iteration: 59400 	loss: 0.017026225104928017
iteration: 59500 	loss: 0.031357523053884506
iteration: 59600 	loss: 0.07763399183750153
iteration: 59700 	loss: 0.03960885852575302
iteration: 59800 	loss: 0.01972648687660694
iteration: 59900 	loss: 0.016950061544775963
iteration: 60000 	loss: 0.015674464404582977
model at iteration 60000 is saved
iteration: 60100 	loss: 0.010847963392734528
iteration: 60200 	loss: 0.014434796757996082
iteration: 60300 	loss: 0.025704968720674515
iteration: 60400 	loss: 0.012300076894462109
iteration: 60500 	loss: 0.02123851329088211
iteration: 60600 	loss: 0.011595208197832108
iteration: 60700 	loss: 0.008987151086330414
iteration: 60800 	loss: 0.01333113107830286
iteration: 60900 	loss: 0.01750018633902073
iteration: 61000 	loss: 0.02643638849258423
iteration: 61100 	loss: 0.009937351569533348
iteration: 61200 	loss: 0.01299947127699852
iteration: 61300 	loss: 0.025739822536706924
iteration: 61400 	loss: 0.012924522161483765
iteration: 61500 	loss: 0.015503201633691788
iteration: 61600 	loss: 0.018681207671761513
iteration: 61700 	loss: 0.04654126986861229
iteration: 61800 	loss: 0.02577662095427513
iteration: 61900 	loss: 0.067753367125988
iteration: 62000 	loss: 0.018794311210513115
iteration: 62100 	loss: 0.013585045002400875
iteration: 62200 	loss: 0.01199160236865282
iteration: 62300 	loss: 0.011112254112958908
iteration: 62400 	loss: 0.016617415472865105
iteration: 62500 	loss: 0.009525471366941929
iteration: 62600 	loss: 0.0076687270775437355
iteration: 62700 	loss: 0.009453840553760529
iteration: 62800 	loss: 0.02179274708032608
iteration: 62900 	loss: 0.012023335322737694
iteration: 63000 	loss: 0.007880885154008865
iteration: 63100 	loss: 0.03615858405828476
iteration: 63200 	loss: 0.02821623720228672
iteration: 63300 	loss: 0.009799283929169178
iteration: 63400 	loss: 0.013824105262756348
iteration: 63500 	loss: 0.03531813994050026
iteration: 63600 	loss: 0.011356532573699951
iteration: 63700 	loss: 0.010337515734136105
iteration: 63800 	loss: 0.01472483854740858
iteration: 63900 	loss: 0.015319284051656723
iteration: 64000 	loss: 0.030635835602879524
model at iteration 64000 is saved
iteration: 64100 	loss: 0.03991422429680824
iteration: 64200 	loss: 0.01165703684091568
iteration: 64300 	loss: 0.0690082460641861
iteration: 64400 	loss: 0.014433656819164753
iteration: 64500 	loss: 0.03313016891479492
iteration: 64600 	loss: 0.02395358681678772
iteration: 64700 	loss: 0.028266794979572296
iteration: 64800 	loss: 0.014529210515320301
iteration: 64900 	loss: 0.01596066541969776
iteration: 65000 	loss: 0.08490099757909775
iteration: 65100 	loss: 0.025497986003756523
iteration: 65200 	loss: 0.013059869408607483
iteration: 65300 	loss: 0.011043721809983253
iteration: 65400 	loss: 0.01254807785153389
iteration: 65500 	loss: 0.010407422669231892
iteration: 65600 	loss: 0.00906574260443449
iteration: 65700 	loss: 0.028550483286380768
iteration: 65800 	loss: 0.0691385418176651
iteration: 65900 	loss: 0.012069598771631718
iteration: 66000 	loss: 0.01962556317448616
iteration: 66100 	loss: 0.1237260103225708
iteration: 66200 	loss: 0.023547932505607605
iteration: 66300 	loss: 0.009370440617203712
iteration: 66400 	loss: 0.07584360986948013
iteration: 66500 	loss: 0.04322762042284012
iteration: 66600 	loss: 0.010326266288757324
iteration: 66700 	loss: 0.03249526768922806
iteration: 66800 	loss: 0.021014690399169922
iteration: 66900 	loss: 0.012147589586675167
iteration: 67000 	loss: 0.038942862302064896
iteration: 67100 	loss: 0.05751768499612808
iteration: 67200 	loss: 0.03789030387997627
iteration: 67300 	loss: 0.016965767368674278
iteration: 67400 	loss: 0.03327491134405136
iteration: 67500 	loss: 0.022185759618878365
iteration: 67600 	loss: 0.0394015796482563
iteration: 67700 	loss: 0.012101277709007263
iteration: 67800 	loss: 0.14172868430614471
iteration: 67900 	loss: 0.06469748914241791
iteration: 68000 	loss: 0.011061154305934906
model at iteration 68000 is saved
iteration: 68100 	loss: 0.008768361993134022
iteration: 68200 	loss: 0.02698143757879734
iteration: 68300 	loss: 0.01414521038532257
iteration: 68400 	loss: 0.025254780426621437
iteration: 68500 	loss: 0.026033606380224228
iteration: 68600 	loss: 0.0810897946357727
iteration: 68700 	loss: 0.04986676946282387
iteration: 68800 	loss: 0.09554344415664673
iteration: 68900 	loss: 0.009242547675967216
iteration: 69000 	loss: 0.011161834932863712
iteration: 69100 	loss: 0.0386575311422348
iteration: 69200 	loss: 0.052311044186353683
iteration: 69300 	loss: 0.026181157678365707
iteration: 69400 	loss: 0.0279373936355114
iteration: 69500 	loss: 0.020597347989678383
iteration: 69600 	loss: 0.012711359187960625
iteration: 69700 	loss: 0.02186468429863453
iteration: 69800 	loss: 0.01941172033548355
iteration: 69900 	loss: 0.025518085807561874
iteration: 70000 	loss: 0.014831721782684326
iteration: 70100 	loss: 0.025086088106036186
iteration: 70200 	loss: 0.02107107639312744
iteration: 70300 	loss: 0.013560990802943707
iteration: 70400 	loss: 0.031842365860939026
iteration: 70500 	loss: 0.009452125057578087
iteration: 70600 	loss: 0.014342610724270344
iteration: 70700 	loss: 0.09754402935504913
iteration: 70800 	loss: 0.013809350319206715
iteration: 70900 	loss: 0.01973937824368477
iteration: 71000 	loss: 0.012063565663993359
iteration: 71100 	loss: 0.006896546576172113
iteration: 71200 	loss: 0.017149589955806732
iteration: 71300 	loss: 0.02329876460134983
iteration: 71400 	loss: 0.0076165031641721725
iteration: 71500 	loss: 0.010740520432591438
iteration: 71600 	loss: 0.022834178060293198
iteration: 71700 	loss: 0.018546370789408684
iteration: 71800 	loss: 0.01620914787054062
iteration: 71900 	loss: 0.014057870954275131
iteration: 72000 	loss: 0.008094805292785168
model at iteration 72000 is saved
iteration: 72100 	loss: 0.09054286777973175
iteration: 72200 	loss: 0.014870943501591682
iteration: 72300 	loss: 0.013097885064780712
iteration: 72400 	loss: 0.030185045674443245
iteration: 72500 	loss: 0.011538001708686352
iteration: 72600 	loss: 0.009015912190079689
iteration: 72700 	loss: 0.008319320157170296
iteration: 72800 	loss: 0.05726427212357521
iteration: 72900 	loss: 0.011898399330675602
iteration: 73000 	loss: 0.01729310117661953
iteration: 73100 	loss: 0.043073296546936035
iteration: 73200 	loss: 0.02000913955271244
iteration: 73300 	loss: 0.009408269077539444
iteration: 73400 	loss: 0.010698423720896244
iteration: 73500 	loss: 0.021715566515922546
iteration: 73600 	loss: 0.03699670359492302
iteration: 73700 	loss: 0.031180694699287415
iteration: 73800 	loss: 0.06661097705364227
iteration: 73900 	loss: 0.10798832029104233
iteration: 74000 	loss: 0.009699222631752491
iteration: 74100 	loss: 0.011677922680974007
iteration: 74200 	loss: 0.011119713075459003
iteration: 74300 	loss: 0.015468583442270756
iteration: 74400 	loss: 0.01002706028521061
iteration: 74500 	loss: 0.009597554802894592
iteration: 74600 	loss: 0.009864076040685177
iteration: 74700 	loss: 0.02132141776382923
iteration: 74800 	loss: 0.013823161832988262
iteration: 74900 	loss: 0.022987108677625656
iteration: 75000 	loss: 0.01393043715506792
iteration: 75100 	loss: 0.03686433285474777
iteration: 75200 	loss: 0.01469824742525816
iteration: 75300 	loss: 0.024500025436282158
iteration: 75400 	loss: 0.00934619177132845
iteration: 75500 	loss: 0.035068634897470474
iteration: 75600 	loss: 0.01944936253130436
iteration: 75700 	loss: 0.0329744927585125
iteration: 75800 	loss: 0.012423891574144363
iteration: 75900 	loss: 0.06647086888551712
iteration: 76000 	loss: 0.01890580542385578
model at iteration 76000 is saved
iteration: 76100 	loss: 0.013988509774208069
iteration: 76200 	loss: 0.02389831468462944
iteration: 76300 	loss: 0.0642780065536499
iteration: 76400 	loss: 0.004803772550076246
iteration: 76500 	loss: 0.010959266684949398
iteration: 76600 	loss: 0.02645614556968212
iteration: 76700 	loss: 0.0157631766051054
iteration: 76800 	loss: 0.024163970723748207
iteration: 76900 	loss: 0.0258722435683012
iteration: 77000 	loss: 0.024705830961465836
iteration: 77100 	loss: 0.03479733318090439
iteration: 77200 	loss: 0.01987895369529724
iteration: 77300 	loss: 0.01713280938565731
iteration: 77400 	loss: 0.018409904092550278
iteration: 77500 	loss: 0.010649344883859158
iteration: 77600 	loss: 0.014198852702975273
iteration: 77700 	loss: 0.014638644643127918
iteration: 77800 	loss: 0.010985242202877998
iteration: 77900 	loss: 0.06448707729578018
iteration: 78000 	loss: 0.014040142297744751
iteration: 78100 	loss: 0.009203849360346794
iteration: 78200 	loss: 0.010820762254297733
iteration: 78300 	loss: 0.025496067479252815
iteration: 78400 	loss: 0.0532587394118309
iteration: 78500 	loss: 0.023385144770145416
iteration: 78600 	loss: 0.039401132613420486
iteration: 78700 	loss: 0.013453042134642601
iteration: 78800 	loss: 0.01983138732612133
iteration: 78900 	loss: 0.028272775933146477
iteration: 79000 	loss: 0.04455503821372986
iteration: 79100 	loss: 0.010149921290576458
iteration: 79200 	loss: 0.0163793433457613
iteration: 79300 	loss: 0.013587422668933868
iteration: 79400 	loss: 0.01955585740506649
iteration: 79500 	loss: 0.008375766687095165
iteration: 79600 	loss: 0.030766412615776062
iteration: 79700 	loss: 0.008768991567194462
iteration: 79800 	loss: 0.06125618889927864
iteration: 79900 	loss: 0.011241811327636242
iteration: 80000 	loss: 0.008166862651705742
model at iteration 80000 is saved
iteration: 80100 	loss: 0.008408935740590096
iteration: 80200 	loss: 0.024956682696938515
iteration: 80300 	loss: 0.08134368062019348
iteration: 80400 	loss: 0.036100875586271286
iteration: 80500 	loss: 0.011345059610903263
iteration: 80600 	loss: 0.010029393248260021
iteration: 80700 	loss: 0.008784698322415352
iteration: 80800 	loss: 0.01594650000333786
iteration: 80900 	loss: 0.01834634132683277
iteration: 81000 	loss: 0.00888502411544323
iteration: 81100 	loss: 0.007799690123647451
iteration: 81200 	loss: 0.03271320462226868
iteration: 81300 	loss: 0.062033120542764664
iteration: 81400 	loss: 0.009925590828061104
iteration: 81500 	loss: 0.02283543348312378
iteration: 81600 	loss: 0.007976733148097992
iteration: 81700 	loss: 0.008729029446840286
iteration: 81800 	loss: 0.04905160889029503
iteration: 81900 	loss: 0.0637873038649559
iteration: 82000 	loss: 0.014100257307291031
iteration: 82100 	loss: 0.017606372013688087
iteration: 82200 	loss: 0.02220587059855461
iteration: 82300 	loss: 0.010309819132089615
iteration: 82400 	loss: 0.0369749441742897
iteration: 82500 	loss: 0.011612373404204845
iteration: 82600 	loss: 0.014717590063810349
iteration: 82700 	loss: 0.015013040974736214
iteration: 82800 	loss: 0.017461152747273445
iteration: 82900 	loss: 0.008569415658712387
iteration: 83000 	loss: 0.0848553255200386
iteration: 83100 	loss: 0.0724724605679512
iteration: 83200 	loss: 0.05308021977543831
iteration: 83300 	loss: 0.01250044908374548
iteration: 83400 	loss: 0.027227839455008507
iteration: 83500 	loss: 0.032117731869220734
iteration: 83600 	loss: 0.012130501680076122
iteration: 83700 	loss: 0.031371112912893295
iteration: 83800 	loss: 0.010069861076772213
iteration: 83900 	loss: 0.01669665239751339
iteration: 84000 	loss: 0.018476702272892
model at iteration 84000 is saved
iteration: 84100 	loss: 0.018588880077004433
iteration: 84200 	loss: 0.01595686748623848
iteration: 84300 	loss: 0.017707815393805504
iteration: 84400 	loss: 0.02106948383152485
iteration: 84500 	loss: 0.012793517671525478
iteration: 84600 	loss: 0.01864566095173359
iteration: 84700 	loss: 0.008188476786017418
iteration: 84800 	loss: 0.009997501969337463
iteration: 84900 	loss: 0.03409352898597717
iteration: 85000 	loss: 0.012678584083914757
iteration: 85100 	loss: 0.038283638656139374
iteration: 85200 	loss: 0.02380540408194065
iteration: 85300 	loss: 0.010845441371202469
iteration: 85400 	loss: 0.025247666984796524
iteration: 85500 	loss: 0.016450928524136543
iteration: 85600 	loss: 0.01745029352605343
iteration: 85700 	loss: 0.0334206148982048
iteration: 85800 	loss: 0.01934395730495453
iteration: 85900 	loss: 0.008818070404231548
iteration: 86000 	loss: 0.08210639655590057
iteration: 86100 	loss: 0.01250552013516426
iteration: 86200 	loss: 0.011598183773458004
iteration: 86300 	loss: 0.017588885501027107
iteration: 86400 	loss: 0.018174612894654274
iteration: 86500 	loss: 0.01798364706337452
iteration: 86600 	loss: 0.020918939262628555
iteration: 86700 	loss: 0.01115448772907257
iteration: 86800 	loss: 0.02152949944138527
iteration: 86900 	loss: 0.008057136088609695
iteration: 87000 	loss: 0.026241831481456757
iteration: 87100 	loss: 0.011206623166799545
iteration: 87200 	loss: 0.03681508079171181
iteration: 87300 	loss: 0.04449673369526863
iteration: 87400 	loss: 0.06480138748884201
iteration: 87500 	loss: 0.015088193118572235
iteration: 87600 	loss: 0.015010673552751541
iteration: 87700 	loss: 0.052985139191150665
iteration: 87800 	loss: 0.021407289430499077
iteration: 87900 	loss: 0.010159939527511597
iteration: 88000 	loss: 0.005904477555304766
model at iteration 88000 is saved
iteration: 88100 	loss: 0.017425119876861572
iteration: 88200 	loss: 0.013583638705313206
iteration: 88300 	loss: 0.047624293714761734
iteration: 88400 	loss: 0.01756017655134201
iteration: 88500 	loss: 0.024576634168624878
iteration: 88600 	loss: 0.0064779543317854404
iteration: 88700 	loss: 0.007824936881661415
iteration: 88800 	loss: 0.017005592584609985
iteration: 88900 	loss: 0.01818585768342018
iteration: 89000 	loss: 0.031071756035089493
iteration: 89100 	loss: 0.008759190328419209
iteration: 89200 	loss: 0.026003209874033928
iteration: 89300 	loss: 0.030925007537007332
iteration: 89400 	loss: 0.044163186103105545
iteration: 89500 	loss: 0.013928153552114964
iteration: 89600 	loss: 0.010760815814137459
iteration: 89700 	loss: 0.09254233539104462
iteration: 89800 	loss: 0.0221780464053154
iteration: 89900 	loss: 0.014869920909404755
iteration: 90000 	loss: 0.016336238011717796
iteration: 90100 	loss: 0.021460499614477158
iteration: 90200 	loss: 0.011464927345514297
iteration: 90300 	loss: 0.033896151930093765
iteration: 90400 	loss: 0.02690620720386505
iteration: 90500 	loss: 0.016470305621623993
iteration: 90600 	loss: 0.045327167958021164
iteration: 90700 	loss: 0.007628576830029488
iteration: 90800 	loss: 0.02522221766412258
iteration: 90900 	loss: 0.01743544265627861
iteration: 91000 	loss: 0.04550587758421898
iteration: 91100 	loss: 0.011988786980509758
iteration: 91200 	loss: 0.013852806761860847
iteration: 91300 	loss: 0.009386415593326092
iteration: 91400 	loss: 0.02941315434873104
iteration: 91500 	loss: 0.012143148109316826
iteration: 91600 	loss: 0.009968509897589684
iteration: 91700 	loss: 0.015498165972530842
iteration: 91800 	loss: 0.025554997846484184
iteration: 91900 	loss: 0.022210363298654556
iteration: 92000 	loss: 0.02245715633034706
model at iteration 92000 is saved
iteration: 92100 	loss: 0.05516926571726799
iteration: 92200 	loss: 0.016932813450694084
iteration: 92300 	loss: 0.011062446050345898
iteration: 92400 	loss: 0.011337321251630783
iteration: 92500 	loss: 0.021893970668315887
iteration: 92600 	loss: 0.019848518073558807
iteration: 92700 	loss: 0.022030537948012352
iteration: 92800 	loss: 0.01407233253121376
iteration: 92900 	loss: 0.03802204132080078
iteration: 93000 	loss: 0.12397076189517975
iteration: 93100 	loss: 0.16061125695705414
iteration: 93200 	loss: 0.01921594887971878
iteration: 93300 	loss: 0.00850364938378334
iteration: 93400 	loss: 0.0353676900267601
iteration: 93500 	loss: 0.013964179903268814
iteration: 93600 	loss: 0.013979383744299412
iteration: 93700 	loss: 0.010961733758449554
iteration: 93800 	loss: 0.02116449363529682
iteration: 93900 	loss: 0.028801605105400085
iteration: 94000 	loss: 0.015113316476345062
iteration: 94100 	loss: 0.0911199152469635
iteration: 94200 	loss: 0.012864356860518456
iteration: 94300 	loss: 0.019837897270917892
iteration: 94400 	loss: 0.013125031255185604
iteration: 94500 	loss: 0.011537017300724983
iteration: 94600 	loss: 0.008706996217370033
iteration: 94700 	loss: 0.017493534833192825
iteration: 94800 	loss: 0.007957941852509975
iteration: 94900 	loss: 0.011849706061184406
iteration: 95000 	loss: 0.029464486986398697
iteration: 95100 	loss: 0.0148259736597538
iteration: 95200 	loss: 0.011319381184875965
iteration: 95300 	loss: 0.03862359747290611
iteration: 95400 	loss: 0.04375555366277695
iteration: 95500 	loss: 0.007767345290631056
iteration: 95600 	loss: 0.028646662831306458
iteration: 95700 	loss: 0.01351792924106121
iteration: 95800 	loss: 0.033162929117679596
iteration: 95900 	loss: 0.012935887090861797
iteration: 96000 	loss: 0.04033935070037842
model at iteration 96000 is saved
iteration: 96100 	loss: 0.01997578889131546
iteration: 96200 	loss: 0.07976940274238586
iteration: 96300 	loss: 0.014384306035935879
iteration: 96400 	loss: 0.0191712137311697
iteration: 96500 	loss: 0.02269528992474079
iteration: 96600 	loss: 0.012919771485030651
iteration: 96700 	loss: 0.0399245023727417
iteration: 96800 	loss: 0.0190165713429451
iteration: 96900 	loss: 0.0075532300397753716
iteration: 97000 	loss: 0.015150978229939938
iteration: 97100 	loss: 0.01476324163377285
iteration: 97200 	loss: 0.01982136443257332
iteration: 97300 	loss: 0.010317943058907986
iteration: 97400 	loss: 0.025581005960702896
iteration: 97500 	loss: 0.027298400178551674
iteration: 97600 	loss: 0.06766241043806076
iteration: 97700 	loss: 0.006967455614358187
iteration: 97800 	loss: 0.008240574970841408
iteration: 97900 	loss: 0.12205492705106735
iteration: 98000 	loss: 0.007111410144716501
iteration: 98100 	loss: 0.035733286291360855
iteration: 98200 	loss: 0.029492691159248352
iteration: 98300 	loss: 0.031868431717157364
iteration: 98400 	loss: 0.013417473062872887
iteration: 98500 	loss: 0.0254976749420166
iteration: 98600 	loss: 0.029372375458478928
iteration: 98700 	loss: 0.02278175763785839
iteration: 98800 	loss: 0.022458545863628387
iteration: 98900 	loss: 0.01184120774269104
iteration: 99000 	loss: 0.013081718236207962
iteration: 99100 	loss: 0.008489761501550674
iteration: 99200 	loss: 0.039415404200553894
iteration: 99300 	loss: 0.01054302603006363
iteration: 99400 	loss: 0.028357908129692078
iteration: 99500 	loss: 0.010128204710781574
iteration: 99600 	loss: 0.00940808467566967
iteration: 99700 	loss: 0.02102283388376236
iteration: 99800 	loss: 0.011954025365412235
iteration: 99900 	loss: 0.021437490358948708
iteration: 100000 	loss: 0.018074827268719673
model at iteration 100000 is saved
iteration: 100100 	loss: 0.017407868057489395
iteration: 100200 	loss: 0.015276001766324043
iteration: 100300 	loss: 0.017053969204425812
